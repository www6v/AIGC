{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d5a0b4-a970-4df3-b37e-5b95ced6e220",
   "metadata": {},
   "source": [
    "# <font face=\"仿宋\">课程说明："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbb07e-7e6e-4b47-9b2c-b06064752fcf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;<font face=\"仿宋\">同学们好呀\\~欢迎来到《大模型技术实战课》试学体验课！我是课程主讲老师，九天。本期体验课主题为《大模型技术入门与Agent开发实战》，将完整介绍目前大模型技术生态，并从零介绍GPT模型API调用方法，同时也将重点介绍目前大模型最为核心的应用方向：Agent开发相关概念，并在课程的结尾手把手带大家完成一个企业级数据分析Agent项目开发！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af7e520-9acd-4e7a-84b3-7f3968043df5",
   "metadata": {},
   "source": [
    "- 体验课内容节选自《大模型技术实战》完整版付费课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa9a853-5d2f-4cfe-a6d9-281cfbbe8c03",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202311151727371.png\" alt=\"cc5b66f28219800ea22a24b3c87cccf\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995bc47-8562-4d14-9b98-89021dc1bf78",
   "metadata": {},
   "source": [
    "**[《大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)招生进行中！【100+小时】体系大课，大模型技术应用【全领域教学】，七大模块精讲精析：        \n",
    "【1】GPT-4模型实战模块           \n",
    "【2】Function calling模块         \n",
    "【3】开源大模型实战模块        \n",
    "【4】词向量数据库实战       \n",
    "【5】大模型微调实战        \n",
    "【6】Agent开发企业级实战        \n",
    "【7】本地知识库问答实战**\n",
    "\n",
    "**此外为持续保证学员大模型技术竞争力，课程实时追更最新大模型技术进展，近期额外新增增了ChatGLM3、GPT-4-turbo和多模态大模型，以及借助Assistant API开发Agent等最新前沿技术内容！课程大纲获取、领取体验课学员专享优惠券，<span style=\"color:red;\">扫码添加客服小可爱(微信：littlecat_1207)，回复“大模型”，即咨询课程信息哦👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276de929-9025-4538-b035-4fada7c17026",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202312271909803.png\" alt=\"1207二维码\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b5a3c-632f-4575-931b-e3f0c2377326",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111450b-b048-4ebc-a0eb-8dba2f35a0c8",
   "metadata": {},
   "source": [
    "# <center> 《大模型技术入门与Agent开发实战》"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffae0e5-8d2c-4634-a2aa-17273e538e19",
   "metadata": {},
   "source": [
    "# <center>Ch 1.4 大模型提示工程入门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19161a7b-dc3f-4267-bb76-b805c4c0ce89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c28fca-b31c-4a20-abef-56f31e026b66",
   "metadata": {},
   "source": [
    "## 一、大模型提示工程入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f1b52-83f8-4b05-bad7-94cb3b3c876b",
   "metadata": {},
   "source": [
    "- 大模型的涌现能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b6e27-da15-4489-a890-6e9de3ea83c9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;GPT3模型是第一批拥有“涌现能力”的大语言模型，即哪怕模型未经特定任务的训练，但在适当的提示下，仍然能够解决某些特定领域的问题。例如大语言模型可以解答数学问题、辅助进行编程、甚至是进行问答等，其实都属于模型的涌现能力。而为何类似数学能力是模型的“涌现能力”，其实原因也并不复杂——作为概率模型，大语言模型甚至不知道数字代表的真实含义，模型只是在学习了无数的语料之后，发现了一些数学结论之间的潜在概率关系，才最终涌现出了数学运算或者复杂推理的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3299c28c-ee76-47f4-b39d-f9ed0edee9cf",
   "metadata": {},
   "source": [
    "> 可能很难想象，能够进行问答，其实也是大语言的涌现能力。大语言模型的训练目标目标是生成或预测文本，而不是进行问答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03084b48-4c26-4fe3-ae2b-abfd701b7ac0",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202312271855045.png\" alt=\"60fae879c6ebfa3a90d870741a15864\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e028d-8251-4243-b48e-e3c743b598aa",
   "metadata": {},
   "source": [
    "- 大模型应用的关键技术——提示工程（Prompt engineering）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a2604-6a35-4578-b4ac-1e7ad99e28d7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不过需要注意的是，大模型的这种“涌现能力”其实并不稳定，在不修改模型本身参数（微调）的情况下，模型涌现能力极度依赖对模型的提示过程，即对同样一个模型，不同的提示方法将获得质量完全不同的结果。而一个完整的用户和大语言模型的交互流程，也被称为大语言模型的提示工程（Prompt engineering），根据此前的描述我们不难理解，提示工程是激发模型涌现能力（激发模型潜力）的非常关键的技术。同时，由于我们对大语言模型“涌现能力”的应用要求是远远多于简单的使用大模型进行文本创建的（毕竟哪怕是对话任务都属于大模型涌现能力的范畴），因此提示工程这一专门用于激发大语言模型涌现能力的技术就变得尤其重要。这也是为何自GPT大模型爆火之后，提示工程便成了非常热门的科研方向，同时提示工程技术也成了大模型应用工程师必不可少的技能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5687730-4bd4-4d96-9ce4-da56b1227772",
   "metadata": {},
   "source": [
    "- 提示工程与模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60870705-22fc-4457-ac12-911a69b16137",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从技术角度来说，提示工程其实是一个易学习门槛很低、但同时技术难度上限又很高的技术。提示工程简单的应用的话，只需要添加一些提示词后缀、或者把问题描述的更加详细即可，而复杂的提示工程，则会涉及多段嵌套提示和极具创造力的围绕中间结果的问答设计等。很遗憾的是，由于大多数非专业人士对大语言模型“浅尝辄止”的使用状态，导致市面上充斥着快餐化的“提示词模板”以及对提示工程粗浅的理解，进而误导很多技术人员觉得提示工程并不重要，而一些看起来技术难度更大、更加高大上的“微调”方法貌似会比提示工程更有效。这其实是一种非常大的误解。微调和提示工程同属对模型涌现能力的引导和优化方法，但相比微调，提示工程成本更低、使用更加灵活，且对于提升模型在小语义空间内复杂语义理解效果更好。当然，在很多时候，我们甚至需要要先设计提示工程进行文本标注，再使用这些标注的文本进行模型微调。不难发现，提示工程技术的学习和掌握，对大模型工程师而言至关重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a12013-6134-44d0-a042-860e07827411",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于ChatCompletion.create函数来说，通过灵活的messages参数，能够非常便捷高效的实现诸多类型的对话需求，例如基于提示词模板的提问、Few-shot提问、基于某背景知识的提问等，接下来我们进一步介绍不同场景下messages参数的设置方法，并在这个过程进一步介绍关于messages中name的设置方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14fab4-0604-4233-be49-aa81253f7850",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于我们接下来需要使用以下四个经典推理问题作为示例，因此我们提前定义好四组问题的问题和答案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc4cbdcc-231e-484a-b4bd-b8a9d0a89c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q1 = '罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？'\n",
    "A1 = '现在罗杰总共有11个网球。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb8c475d-7aab-4003-a842-a1971b2651b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q2 = '食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？'\n",
    "A2 = '现在食堂总共有9个苹果。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97aa8434-271e-41fe-97a4-2367576af28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q3 = '杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？'\n",
    "A3 = '现在总共有4个蓝色高尔夫球。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbae40a0-d539-487e-81f8-80d0e2b3851d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q4 = '艾米需要4分钟才能爬到滑梯顶部，她花了1分钟才滑下来，水滑梯将在15分钟后关闭，请问在关闭之前她能滑多少次？'\n",
    "A4 = '关闭之前艾米能滑3次。'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d058dc-706e-4574-845b-1347a72b3eed",
   "metadata": {},
   "source": [
    "- GPT-3.5推理能力测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a87912-7e9e-475b-96af-b8867eff0ffe",
   "metadata": {},
   "source": [
    "这里需要注意的是，gpt-3.5在解决推理问题上同样展示出了涌现能力，此前的四个推理问题对于gpt-3.5来说，除了最后两个问题具有一定难度外，其他问题均可正常回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "610c793e-63ba-41dc-b349-d45fe125ff18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q1},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "936eccac-0bdb-4fe1-ad98-d4c008c65e16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'罗杰原本有5个网球，又买了两盒网球，每盒有3个网球，所以一共买了2 * 3 = 6个网球。\\n现在总共有5 + 6 = 11个网球。 \\n所以，他现在总共有11个网球。'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "982ec416-7322-4487-850c-9c36226932fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q2},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe08ba53-3c23-4cdb-88a8-c6f52ae8ca1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'食堂现在总共有23 - 20 + 6 = 9个苹果。'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdb56910-f712-47c8-8dbf-cb480e856d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q3},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33147d68-56ad-46e0-994b-78b902260684",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据题意，杂耍者可以杂耍16个球，其中一半是高尔夫球，即8个球是高尔夫球。又已知一半的高尔夫球是蓝色的，即有一半的8个高尔夫球是蓝色的。\\n\\n所以，总共有8个蓝色高尔夫球。'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b4eb065-a9eb-492e-825a-44c9fb2e7ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q4},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e7286cf-2ebf-4b64-9aa2-b8ec2ada3105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在滑梯关闭之前，她能滑的次数取决于她滑下来所需要的时间和滑梯关闭的时间之间的差距。\\n\\n滑下来所需要的时间是1分钟。\\n滑梯关闭的时间是15分钟，即900秒。\\n\\n在滑梯关闭之前，她能滑的次数等于（滑梯关闭时间 - 滑下来所需时间）/ 爬到滑梯顶部所需时间。\\n\\n次数 = (900秒 - 60秒) / 4分钟 = 840秒 / 4分钟 = 210次。\\n\\n所以，在关闭之前，她能滑210次。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b8709-8cfd-47ad-9ea0-e321cb70af41",
   "metadata": {},
   "source": [
    "### 1.Zero-shot与Few-shot提示法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77635e8b-4228-4ee7-84eb-fd9bc2af0c42",
   "metadata": {},
   "source": [
    "- 借助多轮user-assistant消息进行few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08dd94-8540-4563-a86d-7066798ab9a7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先，最为简单的提示工程的方法就是通过输入一些类似问题和问题答案，让模型参考学习，并在同一个prompt的末尾提出新的问题，依次提升模型的推理能力。这种方法也被称为One-shot或者Few-shot提示方法。One-shot和Few-shot最早由OpenAI研究团队在论文[《Language Models are Few-Shot Learners\n",
    "》](https://arxiv.org/pdf/2005.14165.pdf)中率先提出，这篇论文也是提示工程方法开山鼻祖，不仅介绍了提示工程的两大核心方法，同时也详细介绍这么做背后的具体原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e669f14-8045-4280-8aa8-d6a310b9ae17",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果想在Chat模型中进行Few-shot，最好的办法就是在messages中设置多轮user-assistant消息，这里我们还是以Ch.4中的推理问题为例，尝试在Chat模型中进行推理并进行Few-shot，这里我们尝试以第一个问题的问题和答案作为提示示例，引导模型解答第二个问题，则可以按照如下方式设置messages："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3a230b92-d078-497b-97bd-8867948d56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q1},\n",
    "    {\"role\": \"assistant\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "85098713-2de4-4fef-a00c-71d237afda07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在食堂总共有9个苹果。'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eafc47-c115-4425-8ca3-3629f5e43ae8",
   "metadata": {},
   "source": [
    "而相比单独进行Q2的提问，经过Few-shot的提示回答的结果，会更加接近A1结果的表示格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3df73072-a1a8-416b-9efc-597ce1f0d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b77bd16e-19a4-4454-b60c-fb07c931b901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'食堂原本有23个苹果，用掉了20个，剩下3个苹果。\\n然后又买了6个苹果，所以现在食堂总共有3 + 6 = 9个苹果。'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91767e76-2fe3-4168-9623-c9ef6b7a21ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'现在罗杰总共有11个网球。'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad362aae-5b43-451f-a743-49d2719b93dd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在这个示例中，我们能够看出其实assistant消息也是可以自定义的，用于给模型提供回答的范本。并且由此可见messages参数具体呈现形式可以非常多样，不仅可以按照system-user的形式规定回答风格，而且还可以按照user-assistant-user-assistant...形式来进行Few-shot。这其实也是得益于messages高度灵活的参数构成形式——即由多条注明消息源的消息构成。messages中具体每条消息的内容以及消息序列构成形式上，有非常大的调整的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49625cd8-e61e-4660-a539-fca56dcea62b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q1},\n",
    "    {\"role\": \"assistant\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}, \n",
    "    {\"role\": \"assistant\", \"content\": A2},   \n",
    "    {\"role\": \"user\", \"content\": Q3}, \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afbc2f7a-5bcc-4f58-ba79-0fea5de35c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据问题描述，可以得知杂耍者有8个高尔夫球，其中一半的高尔夫球是蓝色的。所以，有4个蓝色的高尔夫球。'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "823c638e-f576-4487-a9b0-33e8aca082be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q1},\n",
    "    {\"role\": \"assistant\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}, \n",
    "    {\"role\": \"assistant\", \"content\": A2},   \n",
    "    {\"role\": \"user\", \"content\": Q3}, \n",
    "    {\"role\": \"assistant\", \"content\": A3},   \n",
    "    {\"role\": \"user\", \"content\": Q4},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4aa89c3-958a-47d5-bec0-0b1e91307ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在关闭之前，艾米可以滑10次。'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581c9bc-b312-47c3-9893-257366f8053d",
   "metadata": {},
   "source": [
    "### 2.思考链COT提示法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd0273-1cef-4698-ac76-fd3b2055a3b7",
   "metadata": {},
   "source": [
    "- 借助system role输入提示模板实现COT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb198ec-dfdd-49f1-9a35-45c224b1b34e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;那有什么办法能够通过更好的提示来提高模型的推理能力呢？最简单的一类办法就是借助思维链（也被称为思考链，Chain of Thought，CoT）提示法来解决这个问题。在这些方法中，最为简单的思维链的实现方法是在提示词尾部追加一句“Let’s think step by step”，即可大幅提高模型推理能力。这种方法最早由东京大学和谷歌在论文[《Large Language Models are Zero-Shot Reasoners》](https://arxiv.org/pdf/2205.11916v2.pdf)中提出。由于只需要修改提示词而无需手动编写推导的成功示例（无需编写思维链样本），因此这种方法也被称为Zero-shot-CoT。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc99c6-28b2-4d08-adfe-451bdae34e9d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据原论文描述，作者在测试Zero_shot_CoT方法时曾尝试过多组不同的提示词尾缀，并在一个机器人指令数据集上进行测试，最终发现“Let’s think step by step”效果最好，其他指令及各指令准确率排名如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639df71d-42f1-486f-9e5f-bb3c47e105bd",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306271728028.png\" alt=\"3f518f011f3ea3af088b67e4512b32b\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c750ab0-d1e9-4df1-b3cd-253e42c4c33d",
   "metadata": {},
   "source": [
    "类似的，就该指令“Let’s think step by step”的中文翻译而言，“请一步步进行推理并得出结论”要远远好于“请让我们一步步进行思考”等类似的提示词语句。这一客观情况也给大模型使用者非常深刻的启发，那就是大模型的“思考过程”是黑箱模型，哪怕表意近似的提示词对模型来说实际的影响力可能会有非常大的区别，围绕提示词的开发需要进行大量的尝试，这个过程也非常类似于掘金的过程。而对于实际使用者而言，则需要平日多注重提示词的积累和尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefd5c9-d95b-4f10-b5f1-f6ba808255ac",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其次，论文中首次提出了利用大模型进行两阶段推理的设想，即第一个阶段先进行问题的拆分并分段解答问题（Reasoning Extraction），然后第二阶段再进行答案的汇总（Answer Extraction）。这一设想尽管没有在论文中进行大量验证，但却给之后的一种名为LEAST-TO-MOST（LtM）的提示方法给予了启发，该方法将在后文中进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c4861-75d6-474b-bcce-5c434f9e0b0e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281608939.png\" alt=\"56bfaaf380a3efc0e47bc54472c7020\" style=\"zoom: 40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a7e61-d816-48e6-a760-93ec200d2a38",
   "metadata": {},
   "source": [
    "&emsp;&emsp;即然system消息能够作为背景设定的基本消息并对后续的问答消息造成影响，那么很容易想到的system消息的一个应用场景就是借助system role输入提示模板，为了更好的提高模型推理能力，我们可以在每个prompt中加入一句“请一步步推理并得出结论”进而实现Zero-shot-CoT。而在Chat模型中，这种prompt模板信息是非常适合通过system role进行输入的，例如围绕第四个推理问题，我们可以通过输入一条内容为“请一步步推理并得出结论”的系统信息，来引导模型完成Zero-shot-CoT："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a47a9ae5-89bd-42d9-947d-d03e35a7a45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_temp_cot = '请一步步思考并解决问题'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a335e89b-9db3-4c43-bfff-7135f25264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_cot},\n",
    "    {\"role\": \"user\", \"content\": Q1}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d3cd6b49-fc8c-4c83-bad6-d6695044bc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'罗杰原本有5个网球\\n他又买了两盒网球，每盒有3个，所以一共买了2盒 × 3个/盒 = 6个网球\\n总共的网球数量为5个 + 6个 = 11个网球'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d29b0-79e7-4983-ae7b-c4588ccb0c32",
   "metadata": {},
   "source": [
    "能够看出，模型确实开始进行了CoT推导。接下来我们测试第四个推理问题、也是最复杂的一个推理问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "607632ea-1eb2-4d15-b882-b46bbbf604fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_cot},\n",
    "    {\"role\": \"user\", \"content\": Q4}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa7ce468-f36c-403a-b0fc-3ed354b14f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'首先，我们需要弄清楚在15分钟内，艾米能够滑下来多少次。\\n\\n艾米每次从滑梯顶部滑下来需要1分钟，所以在15分钟内，她最多可以滑下来15次。\\n\\n然后，我们需要确定艾米每次滑下来后需要多少时间才能再次爬到滑梯顶部。\\n\\n艾米每次滑下来耗时1分钟，所以她需要再花4分钟才能爬到滑梯顶部。所以总共耗时为1分钟下滑时间加上4分钟爬升时间，即为5分钟。\\n\\n最后，我们可以计算出在15分钟内，艾米可以滑多少次。\\n\\n15分钟总共有多少个5分钟？答案是15/5=3个。\\n\\n艾米每次滑下来需要1分钟，所以在15分钟内，她可以滑3次。\\n\\n因此，在关闭之前，艾米可以滑3次。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08747855-652f-4a39-b2ff-43622a1d9a4e",
   "metadata": {},
   "source": [
    "能够看出发现在Zero-shot-CoT的情况下，gpt-3.5模型能够推导得出第四个问题的正确答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a082a-478f-41e8-aa38-283f139f29dc",
   "metadata": {},
   "source": [
    "#### 2.2 Few-shot-CoT提示方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370d9d0-87b4-44f7-b932-aa40a929b1a2",
   "metadata": {},
   "source": [
    "- Few-shot-CoT实现过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea07c9-26a2-407a-baff-9f3822ea2a0f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;哪怕是CoT方法，即然可以Zero-shot-CoT，自然也可以Few-shot-CoT。需要注意的是，Zero-shot-CoT是零样本提示的情况下通过修改提示词后缀激发模型的思维链，而Few-shot-CoT则是通过通过编写思维链样本作为提示词，让模型学会思维链的推导方式，从而更好的完成推导任务。该方法最早由谷歌大脑团队在论文[《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》](https://arxiv.org/pdf/2201.11903.pdf)中首次提出，也是在这篇论文中思维链的概念被首次提出，因此该论文可以说是思维链的开山鼻祖之作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32a34a-5276-43b9-9241-b6849261d387",
   "metadata": {},
   "source": [
    "> 这里需要注意，从诞生时间上来说，Few-shot-CoT诞生时间要早于Zero-shot-CoT，课程中是按照先易后难的顺序编排的内容，所以先介绍Zero-shot-CoT、后介绍Few-shot-CoT。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db629888-5e1f-493b-aca9-717c37004f0b",
   "metadata": {},
   "source": [
    "其实相比于Few-shot，Few-shot-CoT的不同之处只是在于需要在提示样本中不仅给出问题的答案、还同时需要给出问题推导的过程（即思维链），从而让模型学到思维链的推导过程，并将其应用到新的问题中。例如，围绕上述四个推理问题，第一个问题是比较好解决的，我们可以手动写一个思维链作为Few-shot的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7297738f-a750-40f3-9934-72dde90f5936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Q：“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39862f0e-2d39-4c32-a588-015ad9f20350",
   "metadata": {},
   "source": [
    "当然类似这种思维链，也可以借助此前的Zero-shot-CoT来完成创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1c1f7-a0d7-4ebc-973b-dfee205f4b27",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在获得了一个思维链示例后，我们即可以此作为样本进行Few-shot-CoT来解决第最后一个推理问题，具体执行过程如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27a1c90f-0092-42d5-84d2-e694f689f000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？”                         A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。”                         Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？”                         A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。”                         Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？”                         A：“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。”                        '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_Few_shot_CoT3 = 'Q“罗杰有五个网球，他又买了两盒网球，每盒有3个网球，请问他现在总共有多少个网球？” \\\n",
    "                        A：“罗杰一开始有五个网球，又购买了两盒网球，每盒3个，共购买了6个网球，因此现在总共由5+6=11个网球。因此答案是11。” \\\n",
    "                        Q：“食堂总共有23个苹果，如果他们用掉20个苹果，然后又买了6个苹果，请问现在食堂总共有多少个苹果？” \\\n",
    "                        A：“食堂最初有23个苹果，用掉20个，然后又买了6个，总共有23-20+6=9个苹果，答案是9。” \\\n",
    "                        Q：“杂耍者可以杂耍16个球。其中一半的球是高尔夫球，其中一半的高尔夫球是蓝色的。请问总共有多少个蓝色高尔夫球？” \\\n",
    "                        A：“总共有16个球，其中一半是高尔夫球，也就是8个，其中一半是蓝色的，也就是4个，答案是4个。” \\\n",
    "                       '\n",
    "prompt_Few_shot_CoT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8fa38076-af94-4c33-bffb-fd6a9d5616fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_Few_shot_CoT3},\n",
    "    {\"role\": \"user\", \"content\": 'Q:'+Q4}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4018643f-3316-4b46-bab1-7c052525ca93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: 艾米需要4分钟才能爬到滑梯顶部，滑下来只需要1分钟，所以她完成一次滑梯的时间是4+1=5分钟。在滑梯关闭之前，她可以滑的次数是15分钟除以每次滑梯所需时间，即15÷5=3次。所以，在关闭之前她能滑3次滑梯。'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f3c7c-bde6-4917-a1dc-e365aedfa5cf",
   "metadata": {},
   "source": [
    "能够发现，在输入了前三个问题的思维链作为提示词样本，第四个问题已经可以顺利回答了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f6a1bc-5359-4a26-a0e1-1c6465dc5fbd",
   "metadata": {},
   "source": [
    "- 《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》重点结论解读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331bd80-b925-421e-a6ee-4c2ed7933a18",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》是思维链的开山之作，因此论文中提出了大量的关于思维链的应用场景——除了可以用于解决上述推理问题外，思维链还可以被广泛应用于复杂语义理解、符号映射、连贯文本生成等领域。论文中给出了一系列结论，用于论证思维链在这些领域应用的有效性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecdb742-2e20-4e3d-a877-c7671c054b2c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281721637.png\" alt=\"6dca198423a3022cdc8b305829d3795\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2e414-a7f8-4c0f-8c1c-b5f67a5601e8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，论文中还重点强调了模型体量和思维链效果之间的关系，简而言之就是，模型越大、Few-shot-CoT应用效果越好。论文同样以GSM8K数据集为例进行了说明，能够看出模型效果LaMDA（137B）< GPT-3（175B） <  PaLM（540B）。和Zero-shot-CoT类似，模型越大、CoT对模型潜在能力激发效果越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f46bd-a6d0-4d2e-831d-4b4910fab11c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306281840217.png\" alt=\"38ceffed0bdcb0357932f37241660cc\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3821845-5054-4727-b852-23daf01b4cd1",
   "metadata": {},
   "source": [
    "> 这里PaLM具体得分为57分，而Prior supervised best（单独训练的最佳有监督学习模型）得分为55分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b801827-d6a0-40b5-abbd-3b2d2a6fe49b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;就在谷歌大脑提出的CoT被实际验证能够大幅提升大语言模型的推理能力不久，来自谷歌大脑的另一个团队在此基础上发表了另一篇重量级论文《[LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2205.10625.pdf)》，并在其中提出了一种名为Least-to-Most（LtM）的提示方法，将大语言模型的推理能力进一步提高。这种名为LtM的提示方法不仅能够将模型在GSM8K上的表现提高至62%，甚至在某些特殊语义解读场景下能够达到3倍于CoT的效果。不得不说，该方法也是截至目前围绕模型推理能力提升的最为有效的提示学习方法。相关方法方法介绍以及实际应用方法，我们会在正式课程中进行讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e764b06-2af5-4a56-8dc7-5707797f604d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此外，在正式课程中，我们还将更深度的介绍更为复杂的工业级提示工程方法，并用于解决NLP领域的顶尖难题——指令翻译任务：\n",
    "\n",
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306291118609.png\" alt=\"a358c4956cbd8964e7d39b57399ab1d\" style=\"zoom:50%;\" />\n",
    "    \n",
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202306292119088.png\" alt=\"0660614d66dc5b7e0a82398882664da\" style=\"zoom:40%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be826bed-1817-4a7f-be46-265255d38645",
   "metadata": {},
   "source": [
    "## 二、借助提示工程提升自然语言编程能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7dc01-0ce0-4ca1-830d-dfd3183919fb",
   "metadata": {},
   "source": [
    "- 原始问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3b25ed-1313-48a0-ae38-2cfaa729a30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请帮我编写一个多轮对话函数。\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d1e713-3be0-40fb-b05b-33887e5b37fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当然，我可以帮你编写多轮对话函数。请告诉我具体的需求和要实现的功能，然后我们可以一起开始编写代码。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda4915-e6d0-468b-a41b-c805e093a810",
   "metadata": {},
   "source": [
    "- 优化技巧一：清晰准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c422fb9-8026-45c3-a8aa-e6a4caf7475d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1 = \"请帮我编写一个基于OpenAI ChatCompletion.create函数的多轮对话函数。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9780110c-e302-4e24-b41b-590b48a0c7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": q1}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "347ee380-66fe-41d9-bc0d-f3a7889c5abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当然可以！以下是一个基于OpenAI ChatCompletion.create函数的多轮对话函数的示例：\\n\\n```python\\nimport openai\\n\\ndef start_chat(prompt):\\n    # 设置OpenAI API\\n    openai.api_key = \\'YOUR_API_KEY_HERE\\'\\n\\n    # 初始化对话历史\\n    chat_history = []\\n\\n    # 发送初始提示\\n    response = openai.ChatCompletion.create(\\n        model=\"gpt-3.5-turbo\",\\n        messages=[\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n            {\"role\": \"user\", \"content\": prompt}\\n        ]\\n    )\\n\\n    # 提取模型的回复\\n    model_reply = response[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n    \\n    # 将模型的回复添加到对话历史中\\n    chat_history.append(model_reply)\\n\\n    # 返回模型的回复作为初始对话回复\\n    return model_reply\\n\\ndef continue_chat(prompt):\\n    # 检查对话历史是否为空\\n    if len(chat_history) == 0:\\n        return start_chat(prompt)\\n\\n    # 向聊天历史中添加用户输入\\n    chat_history.append(prompt)\\n\\n    # 发送完整的对话历史给模型\\n    response = openai.ChatCompletion.create(\\n        model=\"gpt-3.5-turbo\",\\n        messages=[\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n            {\"role\": \"user\", \"content\": chat_history[-2]},\\n            {\"role\": \"assistant\", \"content\": chat_history[-1]}\\n        ]\\n    )\\n\\n    # 提取模型的回复\\n    model_reply = response[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n    \\n    # 将模型的回复添加到对话历史中\\n    chat_history.append(model_reply)\\n\\n    # 返回模型的回复\\n    return model_reply\\n\\n# 示例对话\\nchat_prompt = \"What\\'s the weather like today?\"\\n\\n# 开始第一次对话\\nchat_reply = start_chat(chat_prompt)\\nprint(\"Assistant:\", chat_reply)\\n\\n# 第一次对话后，继续对话\\nwhile True:\\n    user_input = input(\"User: \")\\n    chat_reply = continue_chat(user_input)\\n    print(\"Assistant:\", chat_reply)\\n```\\n\\n请记得替换示例代码中的YOUR_API_KEY_HERE为您的实际API密钥。您可以在OpenAI的网站上生成API密钥。\\n\\n在这个多轮对话函数中，我们使用了`start_chat`函数作为开始对话时的第一个模型回复，`continue_chat`函数用于之后的每一个用户输入和模型回复。\\n\\n这个函数允许您与模型进行多轮对话，用户输入将被添加到对话历史中，并与上一次模型回复一起发送给模型。模型会根据整个对话历史生成相应的回复。\\n\\n请注意，由于返回的对话历史中包含了所有的消息内容，您在使用模型回复时需要使用合适的格式来提取和展示回复内容。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "995dbf19-13eb-4776-a6c0-5b29bbca3a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "当然可以！以下是一个基于OpenAI ChatCompletion.create函数的多轮对话函数的示例：\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "def start_chat(prompt):\n",
       "    # 设置OpenAI API\n",
       "    openai.api_key = 'YOUR_API_KEY_HERE'\n",
       "\n",
       "    # 初始化对话历史\n",
       "    chat_history = []\n",
       "\n",
       "    # 发送初始提示\n",
       "    response = openai.ChatCompletion.create(\n",
       "        model=\"gpt-3.5-turbo\",\n",
       "        messages=[\n",
       "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "            {\"role\": \"user\", \"content\": prompt}\n",
       "        ]\n",
       "    )\n",
       "\n",
       "    # 提取模型的回复\n",
       "    model_reply = response['choices'][0]['message']['content']\n",
       "    \n",
       "    # 将模型的回复添加到对话历史中\n",
       "    chat_history.append(model_reply)\n",
       "\n",
       "    # 返回模型的回复作为初始对话回复\n",
       "    return model_reply\n",
       "\n",
       "def continue_chat(prompt):\n",
       "    # 检查对话历史是否为空\n",
       "    if len(chat_history) == 0:\n",
       "        return start_chat(prompt)\n",
       "\n",
       "    # 向聊天历史中添加用户输入\n",
       "    chat_history.append(prompt)\n",
       "\n",
       "    # 发送完整的对话历史给模型\n",
       "    response = openai.ChatCompletion.create(\n",
       "        model=\"gpt-3.5-turbo\",\n",
       "        messages=[\n",
       "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "            {\"role\": \"user\", \"content\": chat_history[-2]},\n",
       "            {\"role\": \"assistant\", \"content\": chat_history[-1]}\n",
       "        ]\n",
       "    )\n",
       "\n",
       "    # 提取模型的回复\n",
       "    model_reply = response['choices'][0]['message']['content']\n",
       "    \n",
       "    # 将模型的回复添加到对话历史中\n",
       "    chat_history.append(model_reply)\n",
       "\n",
       "    # 返回模型的回复\n",
       "    return model_reply\n",
       "\n",
       "# 示例对话\n",
       "chat_prompt = \"What's the weather like today?\"\n",
       "\n",
       "# 开始第一次对话\n",
       "chat_reply = start_chat(chat_prompt)\n",
       "print(\"Assistant:\", chat_reply)\n",
       "\n",
       "# 第一次对话后，继续对话\n",
       "while True:\n",
       "    user_input = input(\"User: \")\n",
       "    chat_reply = continue_chat(user_input)\n",
       "    print(\"Assistant:\", chat_reply)\n",
       "```\n",
       "\n",
       "请记得替换示例代码中的YOUR_API_KEY_HERE为您的实际API密钥。您可以在OpenAI的网站上生成API密钥。\n",
       "\n",
       "在这个多轮对话函数中，我们使用了`start_chat`函数作为开始对话时的第一个模型回复，`continue_chat`函数用于之后的每一个用户输入和模型回复。\n",
       "\n",
       "这个函数允许您与模型进行多轮对话，用户输入将被添加到对话历史中，并与上一次模型回复一起发送给模型。模型会根据整个对话历史生成相应的回复。\n",
       "\n",
       "请注意，由于返回的对话历史中包含了所有的消息内容，您在使用模型回复时需要使用合适的格式来提取和展示回复内容。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Code, Markdown\n",
    "display(Markdown(response.choices[0].message['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73f9f3c1-bf4f-4171-a024-32a3e7e1ba8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('example1.md', 'a', encoding='utf-8') as f:\n",
    "    f.write(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb8348-3ea1-4454-85dc-d1395fb90e6f",
   "metadata": {},
   "source": [
    "- 优化技巧二：设置角色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b63146-bc49-4cee-9c86-008b2d21dc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一位擅长编写代码的大模型技术专家。\"},\n",
    "    {\"role\": \"user\", \"content\": q1}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b218a8-285c-4c02-87f1-abfc0604215a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da681b6c-b89a-484b-bb73-3877e02a4da1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "当然可以！以下是一个基于OpenAI ChatCompletion.create函数的多轮对话函数的示例代码：\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "def chat_with_openai(prompt):\n",
       "    # 设置OpenAI的API密钥\n",
       "    openai.api_key = 'your-api-key'\n",
       "\n",
       "    # 初始化对话历史\n",
       "    chat_history = []\n",
       "\n",
       "    while True:\n",
       "        # 构建聊天输入，将对话历史和用户输入拼接起来\n",
       "        user_input = input(\"User: \")\n",
       "        chat_history.append(f\"User: {user_input}\")\n",
       "        chat_history_str = '\\n'.join(chat_history)\n",
       "\n",
       "        # 使用OpenAI API进行聊天\n",
       "        response = openai.ChatCompletion.create(\n",
       "            model=\"gpt-3.5-turbo\",\n",
       "            messages=[\n",
       "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "                {\"role\": \"user\", \"content\": chat_history_str}\n",
       "            ],\n",
       "            max_tokens=50\n",
       "        )\n",
       "\n",
       "        # 解析API响应，提取助手的回复\n",
       "        assistant_reply = response.choices[0].message.content\n",
       "        print(\"Assistant:\", assistant_reply)\n",
       "\n",
       "        # 将助手的回复添加到对话历史中\n",
       "        chat_history.append(f\"Assistant: {assistant_reply}\")\n",
       "\n",
       "        # 当用户输入\"结束对话\"时退出循环\n",
       "        if user_input.lower() == \"end conversation\":\n",
       "            break\n",
       "\n",
       "chat_with_openai(\"Let's start the conversation!\")\n",
       "```\n",
       "\n",
       "在这个示例代码中，我们首先使用`openai.ChatCompletion.create`函数来进行单次的用户输入和助手回复转换。然后，我们将用户输入和助手的回复添加到对话历史中，并将对话历史作为输入传递给下一次API调用。我们重复这个过程，直到用户输入\"end conversation\"来结束对话。\n",
       "\n",
       "需要注意的是，这个示例代码仅用于简单的对话，您可能需要进行一些修改来满足您的具体需求，比如添加其他的聊天逻辑或更复杂的对话历史管理。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec73d719-7fac-4330-89c9-ef244cefd079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('example2.md', 'a', encoding='utf-8') as f:\n",
    "    f.write(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aa719dd-7285-4e90-8fd4-c7f3176ed6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def chat_with_openai(prompt):\n",
    "    # 设置OpenAI的API密钥\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    # 初始化对话历史\n",
    "    chat_history = []\n",
    "\n",
    "    while True:\n",
    "        # 构建聊天输入，将对话历史和用户输入拼接起来\n",
    "        user_input = input(\"User: \")\n",
    "        chat_history.append(f\"User: {user_input}\")\n",
    "        chat_history_str = '\\n'.join(chat_history)\n",
    "\n",
    "        # 使用OpenAI API进行聊天\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": chat_history_str}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 解析API响应，提取助手的回复\n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        print(\"Assistant:\", assistant_reply)\n",
    "\n",
    "        # 将助手的回复添加到对话历史中\n",
    "        chat_history.append(f\"Assistant: {assistant_reply}\")\n",
    "\n",
    "        # 当用户输入\"结束对话\"时退出循环\n",
    "        if user_input.lower() == \"end conversation\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a64416f3-0580-4ea7-9605-e349328f5ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  请问什么是机器学习\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 机器学习是一种人工智能领域的技术，它使计算机能够从数据中学习和改进性能，而不需要进行明确的程序编写。通过利用统计学和算法模型，机器学习可以自动地从大量的数据中发现规律、模式和趋势，并且基于这些发现做出预测和决策。机器学习常被应用于各种领域，如图像识别、语音识别、自然语言处理、推荐系统等，以帮助人们解决复杂的问题和改进现有的系统。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  我的上一个问题是？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 您之前的问题是关于什么是机器学习的。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  end conversation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Assistant: If you have any more questions in the future, feel free to ask. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "chat_with_openai(\"Let's start the conversation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fecd2-e76e-4992-b601-89ca1ac60ad6",
   "metadata": {},
   "source": [
    "- 完整提示策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db1d701-7bc9-4ae5-aa76-2b87e6cdc630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input = \"我现在已经获取了OpenAI API-KEY，并已赋值给openai.api_key。我现在想要编写一个基于ChatCompletion.create函数的多轮对话函数，函数要求如下:\\\n",
    "1.函数无任何必选参数，用户无需输入任何参数即可并开启多轮对话;\\\n",
    "2.当用户输入退出时退出多轮对话;\\\n",
    "3.ChatCompletion.create函数运行过程不设置任何其他参数;\\\n",
    "4.请在函数编写过程中，帮我编写详细的函数说明文档，用于说明函数功能、函数参数情况以及函数返回结果等信息；\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc684de6-c897-47f3-b4e7-5c7769acccc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一位擅长编写代码的大模型技术专家。\"},\n",
    "    {\"role\": \"user\", \"content\": user_input}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11f51bef-85de-4027-8b3a-0fe246d5c5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22a75d74-2498-4afe-9bfc-99ce102acce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "当根据用户输入与AI进行多轮对话时，您可以编写以下函数来实现：\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "def chat_with_ai():\n",
       "    \"\"\"\n",
       "    基于OpenAI GPT-3 API的多轮对话函数\n",
       "\n",
       "    1. 该函数无任何必选参数，用户无需输入任何参数即可开始多轮对话。\n",
       "    2. 当用户输入\"退出\"时，函数将退出多轮对话。\n",
       "    3. 函数使用ChatCompletion.create函数运行AI模型，内部不设置任何其他参数。\n",
       "    \n",
       "    Returns:\n",
       "        response: AI的回复\n",
       "    \n",
       "    Raises:\n",
       "        Exception: 当与API通信发生错误时，将引发异常。\n",
       "\n",
       "    \"\"\"\n",
       "\n",
       "    # 初始化对话过程\n",
       "    user_input = \"\"\n",
       "    conversation_history = []\n",
       "\n",
       "    while user_input.lower() != \"退出\":\n",
       "        # 获取用户输入\n",
       "        user_input = input(\"> \")\n",
       "\n",
       "        # 创建聊天记录，在历史记录中保存用户输入和AI回复\n",
       "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
       "\n",
       "        # 发送请求到 GPT-3 API\n",
       "        try:\n",
       "            response = openai.ChatCompletion.create(\n",
       "                model=\"gpt-3.5-turbo\",\n",
       "                messages=conversation_history\n",
       "            )\n",
       "        except Exception as e:\n",
       "            raise Exception(\"与 GPT-3 API 进行通信时发生错误：\" + str(e))\n",
       "\n",
       "        # 解析 AI 的回复\n",
       "        ai_reply = response.choices[0].message.get(\"content\")\n",
       "\n",
       "        # 打印 AI 回复\n",
       "        print(\"AI:\", ai_reply)\n",
       "\n",
       "        # 在历史记录中保存 AI 回复\n",
       "        conversation_history.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
       "\n",
       "    return ai_reply\n",
       "```\n",
       "\n",
       "这个函数中使用了一个`while`循环来完成多轮对话的过程。在循环中，用户会被要求输入一个问题或指令，然后将其添加到对话历史记录中。然后，调用`ChatCompletion.create`函数与AI模型进行交互，获取AI的回复。AI的回复然后被打印出来并添加到对话历史记录中。循环会一直持续，直到用户输入\"退出\"为止。\n",
       "\n",
       "函数的文档字符串提供了对函数的详细说明，包括函数的功能、参数和返回结果等信息。注意，在调用API时可能会出现异常，因此，我在代码中添加了错误处理以捕获并引发异常，以便您可以捕获并处理错误。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.choices[0].message['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1e040d3-fcdc-4573-8df3-b10615091922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('example3.md', 'a', encoding='utf-8') as f:\n",
    "    f.write(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c569371d-d82d-4a26-86ae-5b98b4ef022f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_with_ai():\n",
    "    \"\"\"\n",
    "    基于OpenAI GPT-3 API的多轮对话函数\n",
    "\n",
    "    1. 该函数无任何必选参数，用户无需输入任何参数即可开始多轮对话。\n",
    "    2. 当用户输入\"退出\"时，函数将退出多轮对话。\n",
    "    3. 函数使用ChatCompletion.create函数运行AI模型，内部不设置任何其他参数。\n",
    "    \n",
    "    Returns:\n",
    "        response: AI的回复\n",
    "    \n",
    "    Raises:\n",
    "        Exception: 当与API通信发生错误时，将引发异常。\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化对话过程\n",
    "    user_input = \"\"\n",
    "    conversation_history = []\n",
    "\n",
    "    while user_input.lower() != \"退出\":\n",
    "        # 获取用户输入\n",
    "        user_input = input(\"> \")\n",
    "\n",
    "        # 创建聊天记录，在历史记录中保存用户输入和AI回复\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # 发送请求到 GPT-3 API\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=conversation_history\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise Exception(\"与 GPT-3 API 进行通信时发生错误：\" + str(e))\n",
    "\n",
    "        # 解析 AI 的回复\n",
    "        ai_reply = response.choices[0].message.get(\"content\")\n",
    "\n",
    "        # 打印 AI 回复\n",
    "        print(\"AI:\", ai_reply)\n",
    "\n",
    "        # 在历史记录中保存 AI 回复\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "\n",
    "    return ai_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba342607-1f23-454f-af42-9336fc9c8fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  你好\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 你好！有什么我可以帮助你的吗？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  请问什么是机器学习？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 机器学习是一种人工智能领域的技术，通过使用算法和模型让计算机系统从经验数据中学习，并根据学习的知识进行预测和决策。它的目标是让计算机具备从数据中获取知识、理解模式和进行自主学习的能力，而无需明确地编程指令。机器学习的过程涉及数据的收集、预处理、特征提取、模型构建、模型训练和评估等步骤。通过机器学习，计算机可以自动发现数据中的规律和模式，从而对未知数据做出预测和判断。机器学习在各个领域都有广泛的应用，如推荐系统、图像识别、自然语言处理等。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  请问我的上一个问题是？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 你上一个问题是“请问什么是机器学习？”\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  退出\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 好的，如果你有任何其他问题，随时可以来问我。再见！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'好的，如果你有任何其他问题，随时可以来问我。再见！'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785494ee-2133-4cfe-b682-c0dbd6b81b3d",
   "metadata": {},
   "source": [
    "- 高阶自然语言编程策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49894c6-65f0-436c-805f-8a4138955e8e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/%E5%A6%82%E4%BD%95%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%BC%95%E5%AF%BC%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E7%BC%96%E7%A8%8B.png\" alt=\"如何更好的引导大语言模型进行编程\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8a079-37f2-41d3-a4ef-84ab2dc70a1d",
   "metadata": {},
   "source": [
    "- 用AI开发AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4010e-4b11-4c6b-bada-b4151f2b6ae7",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/702fe4b67f1781de14a5e217a2d923b.png\" alt=\"702fe4b67f1781de14a5e217a2d923b\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a89642-931a-4450-a0fc-4dac2653e18d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/44740c7f86aa64ce43b217fb9b000fb.png\" alt=\"44740c7f86aa64ce43b217fb9b000fb\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57f5ed-0b58-4d7f-8263-6d58fd36c43f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/code_generate%E5%87%BD%E6%95%B0%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B.png\" alt=\"code_generate函数创建流程\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049180d-0c61-4d57-855c-6d542dbd0379",
   "metadata": {},
   "source": [
    "- 体验课内容节选自《大模型技术实战》完整版付费课程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe304e-f2ed-4d57-91d5-7cdc64d5fe2a",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202311151727371.png\" alt=\"cc5b66f28219800ea22a24b3c87cccf\" style=\"zoom:20%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385297c-15e1-4dac-be27-2f22baf09854",
   "metadata": {},
   "source": [
    "**[《大模型技术实战课》](https://appZe9inzwc2314.h5.xiaoeknow.com)招生进行中！【100+小时】体系大课，大模型技术应用【全领域教学】，七大模块精讲精析：        \n",
    "【1】GPT-4模型实战模块           \n",
    "【2】Function calling模块         \n",
    "【3】开源大模型实战模块        \n",
    "【4】词向量数据库实战       \n",
    "【5】大模型微调实战        \n",
    "【6】Agent开发企业级实战        \n",
    "【7】本地知识库问答实战**\n",
    "\n",
    "**此外为持续保证学员大模型技术竞争力，课程实时追更最新大模型技术进展，近期额外新增增了ChatGLM3、GPT-4-turbo和多模态大模型，以及借助Assistant API开发Agent等最新前沿技术内容！课程大纲获取、领取体验课学员专享优惠券，<span style=\"color:red;\">扫码添加客服小可爱(微信：littlecat_1207)，回复“大模型”，即咨询课程信息哦👇</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405273b-e72f-46f2-93f4-496484514c5d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202312271909803.png\" alt=\"1207二维码\" style=\"zoom:50%;\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openenv",
   "language": "python",
   "name": "openenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
